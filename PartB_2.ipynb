{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFVxWZGJxprU"
      },
      "source": [
        "# CS4001/4042 Assignment 1, Part B, Q2\n",
        "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EycCozG06Duu"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-widedeep -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq0elU0J53Yo",
        "outputId": "44652cb6-c0f3-4de4-b1b9-194f6c966ef1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "\n",
        "import os\n",
        "\n",
        "import random\n",
        "random.seed(SEED)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
        "from pytorch_widedeep.models import TabMlp, WideDeep\n",
        "from pytorch_widedeep import Trainer\n",
        "from pytorch_widedeep.metrics import R2Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU3xdVpwzuLx"
      },
      "source": [
        ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_oYG6lNIh7Mp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('hdb_price_prediction.csv')\n",
        "\n",
        "# TODO: Enter your code here\n",
        "train = df.loc[df['year']<=2020]\n",
        "test = df.loc[df['year']>=2021]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_q9PoR50JAA"
      },
      "source": [
        ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
        "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
        "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
        "features and the categorical features. Use this component to transform the training dataset.\n",
        "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 linear layers in the MLP, with 200 and 100 neurons respectively.\n",
        "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 100 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBY1iqUXtYWn",
        "outputId": "a397e177-d32a-47cc-c861-107e910eca22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:334: UserWarning: Continuous columns will not be normalised\n",
            "  warnings.warn(\"Continuous columns will not be normalised\")\n",
            "epoch 1: 100%|██████████| 1366/1366 [00:19<00:00, 71.55it/s, loss=2.05e+5, metrics={'r2': -1.7222}]\n",
            "epoch 2: 100%|██████████| 1366/1366 [00:17<00:00, 77.71it/s, loss=8.61e+4, metrics={'r2': 0.6364}]\n",
            "epoch 3: 100%|██████████| 1366/1366 [00:17<00:00, 77.14it/s, loss=7.53e+4, metrics={'r2': 0.738}]\n",
            "epoch 4: 100%|██████████| 1366/1366 [00:17<00:00, 77.59it/s, loss=7.07e+4, metrics={'r2': 0.7747}]\n",
            "epoch 5: 100%|██████████| 1366/1366 [00:17<00:00, 80.10it/s, loss=6.86e+4, metrics={'r2': 0.7891}]\n",
            "epoch 6: 100%|██████████| 1366/1366 [00:17<00:00, 76.94it/s, loss=6.68e+4, metrics={'r2': 0.8009}]\n",
            "epoch 7: 100%|██████████| 1366/1366 [00:17<00:00, 77.06it/s, loss=6.55e+4, metrics={'r2': 0.8087}]\n",
            "epoch 8: 100%|██████████| 1366/1366 [00:17<00:00, 77.25it/s, loss=6.46e+4, metrics={'r2': 0.8145}]\n",
            "epoch 9: 100%|██████████| 1366/1366 [00:17<00:00, 76.17it/s, loss=6.38e+4, metrics={'r2': 0.8185}]\n",
            "epoch 10: 100%|██████████| 1366/1366 [00:17<00:00, 77.33it/s, loss=6.32e+4, metrics={'r2': 0.8213}]\n",
            "epoch 11: 100%|██████████| 1366/1366 [00:18<00:00, 75.42it/s, loss=6.27e+4, metrics={'r2': 0.8244}]\n",
            "epoch 12: 100%|██████████| 1366/1366 [00:18<00:00, 74.72it/s, loss=6.24e+4, metrics={'r2': 0.8256}]\n",
            "epoch 13: 100%|██████████| 1366/1366 [00:17<00:00, 77.99it/s, loss=6.22e+4, metrics={'r2': 0.8273}]\n",
            "epoch 14: 100%|██████████| 1366/1366 [00:18<00:00, 73.86it/s, loss=6.18e+4, metrics={'r2': 0.829}]\n",
            "epoch 15: 100%|██████████| 1366/1366 [00:17<00:00, 78.29it/s, loss=6.13e+4, metrics={'r2': 0.8317}]\n",
            "epoch 16: 100%|██████████| 1366/1366 [00:17<00:00, 78.19it/s, loss=6.14e+4, metrics={'r2': 0.831}]\n",
            "epoch 17: 100%|██████████| 1366/1366 [00:17<00:00, 77.57it/s, loss=6.12e+4, metrics={'r2': 0.8323}]\n",
            "epoch 18: 100%|██████████| 1366/1366 [00:17<00:00, 78.03it/s, loss=6.1e+4, metrics={'r2': 0.8328}]\n",
            "epoch 19: 100%|██████████| 1366/1366 [00:17<00:00, 76.97it/s, loss=6.09e+4, metrics={'r2': 0.833}]\n",
            "epoch 20: 100%|██████████| 1366/1366 [00:17<00:00, 76.85it/s, loss=6.07e+4, metrics={'r2': 0.8347}]\n",
            "epoch 21: 100%|██████████| 1366/1366 [00:17<00:00, 78.20it/s, loss=6.07e+4, metrics={'r2': 0.8346}]\n",
            "epoch 22: 100%|██████████| 1366/1366 [00:17<00:00, 77.11it/s, loss=6.03e+4, metrics={'r2': 0.8369}]\n",
            "epoch 23: 100%|██████████| 1366/1366 [00:17<00:00, 80.35it/s, loss=6.04e+4, metrics={'r2': 0.836}]\n",
            "epoch 24: 100%|██████████| 1366/1366 [00:17<00:00, 79.62it/s, loss=6.03e+4, metrics={'r2': 0.8367}]\n",
            "epoch 25: 100%|██████████| 1366/1366 [00:17<00:00, 79.80it/s, loss=6.01e+4, metrics={'r2': 0.8376}]\n",
            "epoch 26: 100%|██████████| 1366/1366 [00:17<00:00, 77.77it/s, loss=6.01e+4, metrics={'r2': 0.8375}]\n",
            "epoch 27: 100%|██████████| 1366/1366 [00:19<00:00, 71.64it/s, loss=6e+4, metrics={'r2': 0.8381}]\n",
            "epoch 28: 100%|██████████| 1366/1366 [00:17<00:00, 76.07it/s, loss=5.98e+4, metrics={'r2': 0.8389}]\n",
            "epoch 29: 100%|██████████| 1366/1366 [00:17<00:00, 78.71it/s, loss=5.99e+4, metrics={'r2': 0.8387}]\n",
            "epoch 30: 100%|██████████| 1366/1366 [00:17<00:00, 78.92it/s, loss=5.96e+4, metrics={'r2': 0.8399}]\n",
            "epoch 31: 100%|██████████| 1366/1366 [00:17<00:00, 79.28it/s, loss=5.96e+4, metrics={'r2': 0.8404}]\n",
            "epoch 32: 100%|██████████| 1366/1366 [00:17<00:00, 79.99it/s, loss=5.95e+4, metrics={'r2': 0.8406}]\n",
            "epoch 33: 100%|██████████| 1366/1366 [00:17<00:00, 78.31it/s, loss=5.95e+4, metrics={'r2': 0.8408}]\n",
            "epoch 34: 100%|██████████| 1366/1366 [00:17<00:00, 78.02it/s, loss=5.97e+4, metrics={'r2': 0.8396}]\n",
            "epoch 35: 100%|██████████| 1366/1366 [00:18<00:00, 75.65it/s, loss=5.96e+4, metrics={'r2': 0.8397}]\n",
            "epoch 36: 100%|██████████| 1366/1366 [00:18<00:00, 74.77it/s, loss=5.92e+4, metrics={'r2': 0.8421}]\n",
            "epoch 37: 100%|██████████| 1366/1366 [00:18<00:00, 73.85it/s, loss=5.94e+4, metrics={'r2': 0.8409}]\n",
            "epoch 38: 100%|██████████| 1366/1366 [00:17<00:00, 77.80it/s, loss=5.94e+4, metrics={'r2': 0.8409}]\n",
            "epoch 39: 100%|██████████| 1366/1366 [00:18<00:00, 74.75it/s, loss=5.9e+4, metrics={'r2': 0.843}]\n",
            "epoch 40: 100%|██████████| 1366/1366 [00:17<00:00, 77.30it/s, loss=5.91e+4, metrics={'r2': 0.8424}]\n",
            "epoch 41: 100%|██████████| 1366/1366 [00:18<00:00, 72.58it/s, loss=5.91e+4, metrics={'r2': 0.8425}]\n",
            "epoch 42: 100%|██████████| 1366/1366 [00:17<00:00, 78.20it/s, loss=5.91e+4, metrics={'r2': 0.8426}]\n",
            "epoch 43: 100%|██████████| 1366/1366 [00:17<00:00, 76.88it/s, loss=5.92e+4, metrics={'r2': 0.842}]\n",
            "epoch 44: 100%|██████████| 1366/1366 [00:17<00:00, 78.71it/s, loss=5.91e+4, metrics={'r2': 0.8425}]\n",
            "epoch 45: 100%|██████████| 1366/1366 [00:17<00:00, 77.75it/s, loss=5.88e+4, metrics={'r2': 0.8437}]\n",
            "epoch 46: 100%|██████████| 1366/1366 [00:17<00:00, 76.12it/s, loss=5.89e+4, metrics={'r2': 0.8431}]\n",
            "epoch 47: 100%|██████████| 1366/1366 [00:17<00:00, 76.03it/s, loss=5.9e+4, metrics={'r2': 0.8432}]\n",
            "epoch 48: 100%|██████████| 1366/1366 [00:17<00:00, 78.96it/s, loss=5.89e+4, metrics={'r2': 0.8434}]\n",
            "epoch 49: 100%|██████████| 1366/1366 [00:18<00:00, 75.74it/s, loss=5.89e+4, metrics={'r2': 0.8431}]\n",
            "epoch 50: 100%|██████████| 1366/1366 [00:16<00:00, 80.49it/s, loss=5.89e+4, metrics={'r2': 0.8436}]\n",
            "epoch 51: 100%|██████████| 1366/1366 [00:17<00:00, 76.38it/s, loss=5.86e+4, metrics={'r2': 0.8449}]\n",
            "epoch 52: 100%|██████████| 1366/1366 [00:17<00:00, 77.15it/s, loss=5.87e+4, metrics={'r2': 0.8443}]\n",
            "epoch 53: 100%|██████████| 1366/1366 [00:17<00:00, 77.35it/s, loss=5.87e+4, metrics={'r2': 0.8444}]\n",
            "epoch 54: 100%|██████████| 1366/1366 [00:17<00:00, 76.61it/s, loss=5.87e+4, metrics={'r2': 0.8448}]\n",
            "epoch 55: 100%|██████████| 1366/1366 [00:18<00:00, 72.97it/s, loss=5.87e+4, metrics={'r2': 0.8446}]\n",
            "epoch 56: 100%|██████████| 1366/1366 [00:17<00:00, 77.07it/s, loss=5.86e+4, metrics={'r2': 0.8449}]\n",
            "epoch 57: 100%|██████████| 1366/1366 [00:17<00:00, 79.57it/s, loss=5.87e+4, metrics={'r2': 0.8445}]\n",
            "epoch 58: 100%|██████████| 1366/1366 [00:18<00:00, 75.47it/s, loss=5.85e+4, metrics={'r2': 0.8458}]\n",
            "epoch 59: 100%|██████████| 1366/1366 [00:17<00:00, 76.97it/s, loss=5.85e+4, metrics={'r2': 0.8455}]\n",
            "epoch 60: 100%|██████████| 1366/1366 [00:18<00:00, 75.32it/s, loss=5.85e+4, metrics={'r2': 0.8457}]\n",
            "epoch 61: 100%|██████████| 1366/1366 [00:18<00:00, 74.92it/s, loss=5.85e+4, metrics={'r2': 0.8452}]\n",
            "epoch 62: 100%|██████████| 1366/1366 [00:17<00:00, 75.96it/s, loss=5.83e+4, metrics={'r2': 0.8463}]\n",
            "epoch 63: 100%|██████████| 1366/1366 [00:17<00:00, 76.13it/s, loss=5.85e+4, metrics={'r2': 0.8457}]\n",
            "epoch 64: 100%|██████████| 1366/1366 [00:18<00:00, 75.22it/s, loss=5.83e+4, metrics={'r2': 0.8463}]\n",
            "epoch 65: 100%|██████████| 1366/1366 [00:17<00:00, 77.18it/s, loss=5.84e+4, metrics={'r2': 0.846}]\n",
            "epoch 66: 100%|██████████| 1366/1366 [00:17<00:00, 77.48it/s, loss=5.84e+4, metrics={'r2': 0.846}]\n",
            "epoch 67: 100%|██████████| 1366/1366 [00:17<00:00, 76.37it/s, loss=5.82e+4, metrics={'r2': 0.8468}]\n",
            "epoch 68: 100%|██████████| 1366/1366 [00:18<00:00, 74.13it/s, loss=5.82e+4, metrics={'r2': 0.8469}]\n",
            "epoch 69: 100%|██████████| 1366/1366 [00:19<00:00, 71.81it/s, loss=5.83e+4, metrics={'r2': 0.8459}]\n",
            "epoch 70: 100%|██████████| 1366/1366 [00:17<00:00, 76.40it/s, loss=5.82e+4, metrics={'r2': 0.8469}]\n",
            "epoch 71: 100%|██████████| 1366/1366 [00:18<00:00, 74.68it/s, loss=5.82e+4, metrics={'r2': 0.8467}]\n",
            "epoch 72: 100%|██████████| 1366/1366 [00:18<00:00, 72.91it/s, loss=5.8e+4, metrics={'r2': 0.8476}]\n",
            "epoch 73: 100%|██████████| 1366/1366 [00:17<00:00, 78.56it/s, loss=5.82e+4, metrics={'r2': 0.8467}]\n",
            "epoch 74: 100%|██████████| 1366/1366 [00:18<00:00, 74.61it/s, loss=5.8e+4, metrics={'r2': 0.8478}]\n",
            "epoch 75: 100%|██████████| 1366/1366 [00:18<00:00, 74.26it/s, loss=5.81e+4, metrics={'r2': 0.8474}]\n",
            "epoch 76: 100%|██████████| 1366/1366 [00:17<00:00, 77.24it/s, loss=5.79e+4, metrics={'r2': 0.8484}]\n",
            "epoch 77: 100%|██████████| 1366/1366 [00:18<00:00, 75.61it/s, loss=5.8e+4, metrics={'r2': 0.848}]\n",
            "epoch 78: 100%|██████████| 1366/1366 [00:18<00:00, 74.51it/s, loss=5.77e+4, metrics={'r2': 0.8493}]\n",
            "epoch 79: 100%|██████████| 1366/1366 [00:18<00:00, 73.09it/s, loss=5.79e+4, metrics={'r2': 0.8482}]\n",
            "epoch 80: 100%|██████████| 1366/1366 [00:17<00:00, 76.03it/s, loss=5.79e+4, metrics={'r2': 0.8482}]\n",
            "epoch 81: 100%|██████████| 1366/1366 [00:18<00:00, 72.34it/s, loss=5.78e+4, metrics={'r2': 0.8486}]\n",
            "epoch 82: 100%|██████████| 1366/1366 [00:19<00:00, 69.57it/s, loss=5.77e+4, metrics={'r2': 0.8494}]\n",
            "epoch 83: 100%|██████████| 1366/1366 [00:19<00:00, 71.83it/s, loss=5.78e+4, metrics={'r2': 0.8489}]\n",
            "epoch 84: 100%|██████████| 1366/1366 [00:18<00:00, 71.96it/s, loss=5.78e+4, metrics={'r2': 0.8489}]\n",
            "epoch 85: 100%|██████████| 1366/1366 [00:18<00:00, 73.26it/s, loss=5.78e+4, metrics={'r2': 0.8492}]\n",
            "epoch 86: 100%|██████████| 1366/1366 [00:17<00:00, 76.87it/s, loss=5.75e+4, metrics={'r2': 0.8505}]\n",
            "epoch 87: 100%|██████████| 1366/1366 [00:18<00:00, 74.96it/s, loss=5.76e+4, metrics={'r2': 0.8499}]\n",
            "epoch 88: 100%|██████████| 1366/1366 [00:18<00:00, 74.39it/s, loss=5.74e+4, metrics={'r2': 0.8507}]\n",
            "epoch 89: 100%|██████████| 1366/1366 [00:18<00:00, 75.33it/s, loss=5.73e+4, metrics={'r2': 0.8516}]\n",
            "epoch 90: 100%|██████████| 1366/1366 [00:18<00:00, 74.97it/s, loss=5.69e+4, metrics={'r2': 0.8534}]\n",
            "epoch 91: 100%|██████████| 1366/1366 [00:18<00:00, 73.87it/s, loss=5.65e+4, metrics={'r2': 0.8555}]\n",
            "epoch 92: 100%|██████████| 1366/1366 [00:18<00:00, 74.19it/s, loss=5.61e+4, metrics={'r2': 0.8579}]\n",
            "epoch 93: 100%|██████████| 1366/1366 [00:17<00:00, 76.98it/s, loss=5.53e+4, metrics={'r2': 0.8617}]\n",
            "epoch 94: 100%|██████████| 1366/1366 [00:18<00:00, 73.52it/s, loss=5.44e+4, metrics={'r2': 0.8664}]\n",
            "epoch 95: 100%|██████████| 1366/1366 [00:18<00:00, 73.09it/s, loss=5.31e+4, metrics={'r2': 0.8726}]\n",
            "epoch 96: 100%|██████████| 1366/1366 [00:19<00:00, 71.04it/s, loss=5.24e+4, metrics={'r2': 0.876}]\n",
            "epoch 97: 100%|██████████| 1366/1366 [00:18<00:00, 73.70it/s, loss=5.2e+4, metrics={'r2': 0.8783}]\n",
            "epoch 98: 100%|██████████| 1366/1366 [00:19<00:00, 71.32it/s, loss=5.16e+4, metrics={'r2': 0.8795}]\n",
            "epoch 99: 100%|██████████| 1366/1366 [00:18<00:00, 72.93it/s, loss=5.14e+4, metrics={'r2': 0.8805}]\n",
            "epoch 100: 100%|██████████| 1366/1366 [00:18<00:00, 73.03it/s, loss=5.09e+4, metrics={'r2': 0.8828}]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Enter your code here\n",
        "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
        "\n",
        "target = train['resale_price']\n",
        "num_col_names = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
        "cat_col_names = ['month', 'town', 'flat_model_type', 'storey_range']\n",
        "\n",
        "cat_embed_cols = [\n",
        "    (i, train[i].nunique()) for i in cat_col_names\n",
        "]\n",
        "continuous_cols = num_col_names\n",
        "\n",
        "tab_preprocessor = TabPreprocessor(\n",
        "    cat_embed_cols=cat_embed_cols, continuous_cols=continuous_cols\n",
        ")\n",
        "X_tab = tab_preprocessor.fit_transform(train)\n",
        "\n",
        "\n",
        "model = TabMlp(\n",
        "    column_idx=tab_preprocessor.column_idx,\n",
        "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
        "    continuous_cols=continuous_cols,\n",
        "    mlp_hidden_dims=[200, 100]\n",
        ")\n",
        "\n",
        "model = WideDeep(deeptabular=model)\n",
        "trainer = Trainer(model, cost_function=\"root_mean_squared_error\", metrics=[R2Score], num_workers=0)\n",
        "trainer.fit(\n",
        "    X_tab=X_tab,\n",
        "    target=target,\n",
        "    n_epochs=100,\n",
        "    batch_size=64,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V46s-MdM0y5c"
      },
      "source": [
        ">Report the test RMSE and the test R2 value that you obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAhAgvMC07g6",
        "outputId": "900aa0ee-671e-43a6-b6ec-56895a997b9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "predict: 100%|██████████| 1128/1128 [00:07<00:00, 150.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2: 0.6700669822233035\n",
            "RMSE: 97177.03065945236\n"
          ]
        }
      ],
      "source": [
        "# TODO: Enter your code here\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "X_tab_test = tab_preprocessor.transform(test)\n",
        "y_pred = trainer.predict(X_tab=X_tab_test, batch_size=64)\n",
        "\n",
        "y = test['resale_price']\n",
        "rmse = mean_squared_error(y, y_pred, squared=False)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(f\"R2: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWFiBwjIqp_U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
